{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFFCx5J80SGa"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/liujing04/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmFP6bN9dvOq"
      },
      "outputs": [],
      "source": [
        "# Check the specifications of the available GPU (Graphics Processing Unit)\n",
        "# The following command checks which GPU is present and shows its usage, names, and other details.\n",
        "# \"nvidia-smi\" is a system management interface command for NVIDIA GPU products.\n",
        "# This command provides information on the GPU and its capabilities, as well as statistics on its utilization and temperature.\n",
        "\n",
        "# @title Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjddIFr1oS3W"
      },
      "outputs": [],
      "source": [
        "# Install required system packages\n",
        "# The following command installs necessary system packages, including build tools and libraries for Python development and FFmpeg for audio manipulation.\n",
        "!apt-get -y install build-essential python3-dev ffmpeg\n",
        "\n",
        "# Upgrade setuptools and wheel packages\n",
        "# These packages are important for installing some Python libraries and managing their dependencies.\n",
        "!pip3 install --upgrade setuptools wheel\n",
        "\n",
        "# Upgrade pip package installer\n",
        "# This ensures that the latest version of pip is being used, allowing for proper installation of library packages.\n",
        "!pip3 install --upgrade pip\n",
        "\n",
        "# Install required Python libraries\n",
        "# The following command installs the necessary Python libraries for the project, specifying specific versions where needed.\n",
        "# These libraries include:\n",
        "# faiss-gpu: Facebook AI Similarity Search library with GPU support\n",
        "# fairseq: A sequence-to-sequence learning toolkit from Facebook AI Research\n",
        "# gradio: A library for creating easy-to-use UI components for ML models\n",
        "# ffmpeg, ffmpeg-python: Libraries for handling multimedia files\n",
        "# praat-parselmouth: A library to interface with the Praat software for phonetic analysis\n",
        "# pyworld: A world-class speech analysis, manipulation, and synthesis system\n",
        "# numpy, numba, librosa: Libraries for numerical operations and audio processing\n",
        "!pip3 install faiss-gpu fairseq gradio ffmpeg ffmpeg-python praat-parselmouth pyworld numpy==1.23.5 numba==0.56.4 librosa==0.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge_97mfpgqTm"
      },
      "outputs": [],
      "source": [
        "# Clone the \"Retrieval-based Voice Conversion WebUI\" repository\n",
        "# This command downloads the stable branch of the repository and navigates into the downloaded folder.\n",
        "!git clone --depth=1 -b main https://github.com/developer787/Retrieval-based-Voice-Conversion-WebUI\n",
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "\n",
        "# Create directories for holding pre-trained models and UVR5 weights\n",
        "# This command creates the necessary folders for storing pre-trained models and the weights for the UVR5 model.\n",
        "!mkdir -p pretrained uvr5_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLDEZADkvlw1"
      },
      "outputs": [],
      "source": [
        "# Update the repository (generally not needed)\n",
        "# This command, when executed, updates the cloned repository with the latest changes from the remote repository.\n",
        "# Note that this command is usually not needed as the codebase should already be up to date.\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqE0PrnuRqI2"
      },
      "outputs": [],
      "source": [
        "# Install aria2 downloader\n",
        "# aria2 is a lightweight multi-protocol & multi-source command-line download utility.\n",
        "# It supports HTTP/HTTPS, FTP, and BitTorrent, and optimizes multi-connection downloads.\n",
        "# The following command installs aria2, using the \"-qq\" flag to minimize output.\n",
        "!apt -y install -qq aria2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG3XpUwEomUz"
      },
      "outputs": [],
      "source": [
        "# Download base models\n",
        "# These commands use the aria2 downloader to download pre-trained models for the voice conversion system.\n",
        "# The models are downloaded from the Hugging Face Model Hub, specifying the filenames and directory locations.\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0G48k.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HugjmZqZRuiF"
      },
      "outputs": [],
      "source": [
        "# Download voice separation models\n",
        "# Use aria2 to download the pretrained voice separation models from HuggingFace hub with optimized multi-connection settings.\n",
        "# HP2 model: separates vocals and non-vocal instrumental parts\n",
        "# HP5 model: separates main melody vocals and other instrumental parts\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP2-人声vocals+非人声instrumentals.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/uvr5_weights -o HP2-人声vocals+非人声instrumentals.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP5-主旋律人声vocals+其他instrumentals.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/uvr5_weights -o HP5-主旋律人声vocals+其他instrumentals.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RCaT9FTR0ej"
      },
      "outputs": [],
      "source": [
        "# Download the Hubert Base model\n",
        "# Use aria2 to download the pretrained Hubert Base model from HuggingFace hub with optimized multi-connection settings.\n",
        "# Hubert is a self-supervised speech model developed by Facebook AI Research.\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt -d /content/Retrieval-based-Voice-Conversion-WebUI -o hubert_base.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwu07JgqoFON"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "# This command allows you to access your Google Drive files in the Colab environment.\n",
        "# A prompt will ask you to authenticate and grant access permissions.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwk7Q0Loqzjx"
      },
      "outputs": [],
      "source": [
        "# Load the packaged dataset from Google Drive to /content/dataset\n",
        "# This command creates a new directory at \"/content/dataset\" and unzips the dataset from Google Drive into that directory.\n",
        "\n",
        "# Dataset location (in Google Drive)\n",
        "DATASET = \"/content/drive/MyDrive/dataset/lulu20230327_32k.zip\"  # @param {type:\"string\"}\n",
        "\n",
        "# Create a directory to store the dataset at \"/content/dataset\"\n",
        "!mkdir -p /content/dataset\n",
        "\n",
        "# Unzip the dataset into the created directory\n",
        "!unzip -d /content/dataset -B {DATASET}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDlFxWHWEynD"
      },
      "outputs": [],
      "source": [
        "# Rename duplicate filenames in the dataset\n",
        "# The following commands are used to display the current file names in the dataset directory\n",
        "# and to rename any duplicate files using a regex pattern.\n",
        "\n",
        "# List all files in the /content/dataset/ directory\n",
        "!ls -a /content/dataset/\n",
        "\n",
        "# Rename duplicate files using a regex pattern\n",
        "# This command uses the 'rename' utility to replace the \"~\" in the file name with an underscore.\n",
        "# For example: \"file.wav~1\" will be renamed to \"file_1.wav\"\n",
        "!rename 's/(\\w+)\\.(\\w+)~(\\d*)/$1_$3.$2/' /content/dataset/*.*~*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vh6vphDwO0b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Start the Web Interface\n",
        "# Change to the project directory and start the web interface using the \"infer-web.py\" script.\n",
        "# The \"--colab\" and \"--pycmd python3\" flags are used to configure the script for Google Colaboratory and specify that Python 3 is being used.\n",
        "\n",
        "# Change to the project directory\n",
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "\n",
        "# Uncomment the following lines for loading TensorBoard and visualizing logs.\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir /content/Retrieval-based-Voice-Conversion-WebUI/logs\n",
        "\n",
        "# Start the web interface using the \"infer-web.py\" script\n",
        "!python3 infer-web.py --colab --pycmd python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgJuNeAwx5Y_"
      },
      "outputs": [],
      "source": [
        "# Manually backup trained model files to Google Drive\n",
        "# You need to check the model file names in the logs folder and manually modify the file names accordingly in the commands below.\n",
        "\n",
        "# Define the variables for model name and epoch\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "# Copy Generator and Discriminator model files to Google Drive\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "\n",
        "# Copy index and .npy files to Google Drive\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/added_*.index /content/drive/MyDrive/\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/total_*.npy /content/drive/MyDrive/\n",
        "\n",
        "# Copy weights (model) file to Google Drive\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/weights/{MODELNAME}.pth /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVQoLQJXS7WX"
      },
      "outputs": [],
      "source": [
        "# Restore .pth files from Google Drive\n",
        "# You need to check the model file names in the logs folder and manually modify the file names accordingly in the commands below.\n",
        "\n",
        "# Define the variables for model name and epoch\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "MODELEPOCH = 7500  # @param {type:\"integer\"}\n",
        "\n",
        "# Create the required directory for storing logs\n",
        "!mkdir -p /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "\n",
        "# Copy Generator and Discriminator model files from Google Drive\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "\n",
        "# Copy index and .npy files from Google Drive\n",
        "!cp /content/drive/MyDrive/*.index /content/\n",
        "!cp /content/drive/MyDrive/*.npy /content/\n",
        "\n",
        "# Copy weights (model) file from Google Drive\n",
        "!cp /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/weights/{MODELNAME}.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKAyuKb9J6dz"
      },
      "outputs": [],
      "source": [
        "# Manual Preprocessing (Not Recommended)\n",
        "# This section allows for customizing the preprocessing pipeline using specific values for model name, sampling rate, and number of processes.\n",
        "# Note: Manual preprocessing is not recommended for most use cases.\n",
        "\n",
        "# Specify model name, sampling rate, and number of processes\n",
        "MODELNAME = \"lulu\"  #@param {type:\"string\"}\n",
        "BITRATE = 48000  #@param {type:\"integer\"}\n",
        "THREADCOUNT = 8  #@param {type:\"integer\"}\n",
        "\n",
        "# Run the preprocessing pipeline script with the specified parameters\n",
        "!python3 trainset_preprocess_pipeline_print.py /content/dataset {BITRATE} {THREADCOUNT} logs/{MODELNAME} True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrxJqzAUKmPJ"
      },
      "outputs": [],
      "source": [
        "# Manual Feature Extraction (Not Recommended)\n",
        "# This section allows for customizing the feature extraction pipeline using specific values for model name, number of processes, and pitch extraction algorithm.\n",
        "# Note: Manual feature extraction is not recommended for most use cases.\n",
        "\n",
        "# Specify model name, number of processes, and pitch extraction algorithm\n",
        "MODELNAME = \"lulu\"  #@param {type:\"string\"}\n",
        "THREADCOUNT = 8  #@param {type:\"integer\"}\n",
        "ALGO = \"harvest\"  #@param {type:\"string\"}\n",
        "\n",
        "# Run the F0 extraction script with the specified parameters\n",
        "!python3 extract_f0_print.py logs/{MODELNAME} {THREADCOUNT} {ALGO}\n",
        "\n",
        "# Run the feature extraction script with the specified parameters\n",
        "!python3 extract_feature_print.py cpu 1 0 0 logs/{MODELNAME}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMLPLKOaKj58"
      },
      "outputs": [],
      "source": [
        "# Manual Training (Not Recommended)\n",
        "# This section allows for customizing the training process using specific values for model name, GPU, batch size, epochs, sampling rate, and other parameters.\n",
        "# Note: Manual training is not recommended for most use cases.\n",
        "\n",
        "# Specify training parameters\n",
        "MODELNAME = \"lulu\"  #@param {type:\"string\"}\n",
        "USEGPU = \"0\"  #@param {type:\"string\"}\n",
        "BATCHSIZE = 32  #@param {type:\"integer\"}\n",
        "MODELEPOCH = 3200  #@param {type:\"integer\"}\n",
        "EPOCHSAVE = 100  #@param {type:\"integer\"}\n",
        "MODELSAMPLE = \"48k\"  #@param {type:\"string\"}\n",
        "CACHEDATA = 1  #@param {type:\"integer\"}\n",
        "ONLYLATEST = 0  #@param {type:\"integer\"}\n",
        "\n",
        "# Run the training script with the specified parameters\n",
        "!python3 train_nsf_sim_cache_sid_load_pretrain.py -e lulu -sr {MODELSAMPLE} -f0 1 -bs {BATCHSIZE} -g {USEGPU} -te {MODELEPOCH} -se {EPOCHSAVE} -pg pretrained/f0G{MODELSAMPLE}.pth -pd pretrained/f0D{MODELSAMPLE}.pth -l {ONLYLATEST} -c {CACHEDATA}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haYA81hySuDl"
      },
      "outputs": [],
      "source": [
        "# Caution: This section deletes all other .pth files and leaves only the selected one.\n",
        "# Carefully review the code before running this cell.\n",
        "\n",
        "# Specify model name and selected model epoch\n",
        "MODELNAME = \"lulu\"  #@param {type:\"string\"}\n",
        "MODELEPOCH = 9600  #@param {type:\"integer\"}\n",
        "\n",
        "# Backup the selected model\n",
        "!echo \"Backing up the selected model...\"\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "\n",
        "# Delete other .pth files\n",
        "!echo \"Deleting other files...\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "!rm /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/*.pth\n",
        "\n",
        "# Restore the selected model\n",
        "!echo \"Restoring the selected model...\"\n",
        "!mv /content/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!mv /content/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "\n",
        "# Confirm the deletion is completed\n",
        "!echo \"Deletion completed\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhSiPTVPoIRh"
      },
      "outputs": [],
      "source": [
        "# Clear all files under the project and keep only the selected model (Use with caution, review the code carefully)\n",
        "# This script allows you to delete all the files under the project directory, \n",
        "# keeping only the selected model's generator and discriminator weights.\n",
        "\n",
        "# Specify the model name and model epoch\n",
        "MODELNAME = \"lulu\"  #@param {type:\"string\"}\n",
        "MODELEPOCH = 9600  #@param {type:\"integer\"}\n",
        "\n",
        "# Back up the selected model's generator and discriminator weights\n",
        "!echo \"Backing up the selected model...\"\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "\n",
        "# Delete all files under the project's logs directory for the specified model\n",
        "!echo \"Deleting...\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "!rm -rf /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/*\n",
        "\n",
        "# Restore the backed-up generator and discriminator weights\n",
        "!echo \"Restoring the selected model...\"\n",
        "!mv /content/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!mv /content/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "\n",
        "# Verify that the deletion and restoration are complete\n",
        "!echo \"Deletion completed\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
